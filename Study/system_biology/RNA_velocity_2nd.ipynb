{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "center-market",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-latvia",
   "metadata": {},
   "source": [
    "conda install numpy scipy cython numba matplotlib scikit-learn h5py click"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-survivor",
   "metadata": {},
   "source": [
    "### cython\n",
    "The Cython language makes writing C extensions for the Python language as easy as Python itself. Cython is a source code translator based on Pyrex, but supports more cutting edge functionality and optimizations.\n",
    "\n",
    "The Cython language is a superset of the Python language (almost all Python code is also valid Cython code), but Cython additionally supports optional static typing to natively call C functions, operate with C++ classes and declare fast C types on variables and class attributes. This allows the compiler to generate very efficient C code from Cython code.\n",
    "\n",
    "### numba\n",
    "\n",
    "Numba translates Python functions to optimized machine code at runtime using the industry-standard LLVM compiler library. Numba-compiled numerical algorithms in Python can approach the speeds of C or FORTRAN.\n",
    "\n",
    "### h5py\n",
    "The h5py package provides both a high- and low-level interface to the HDF5 library from Python. The low-level interface is intended to be a complete wrapping of the HDF5 API, while the high-level component supports access to HDF5 files, datasets and groups using established Python and NumPy concepts.\n",
    "\n",
    "A strong emphasis on automatic conversion between Python (Numpy) datatypes and data structures and their HDF5 equivalents vastly simplifies the process of reading and writing data from Python.\n",
    "\n",
    "### click\n",
    "lick is a Python package for creating beautiful command line interfaces in a composable way with as little code as necessary. It’s the “Command Line Interface Creation Kit”. It’s highly configurable but comes with sensible defaults out of the box.\n",
    "\n",
    "It aims to make the process of writing command line tools quick and fun while also preventing any frustration caused by the inability to implement an intended CLI API.\n",
    "\n",
    "Click in three points:\n",
    "\n",
    "arbitrary nesting of commands\n",
    "\n",
    "automatic help page generation\n",
    "\n",
    "supports lazy loading of subcommands at runtime\n",
    "\n",
    "### pysam (prefer to use pip)\n",
    "pysam - a python module for reading, manipulating and writing genomic data sets.\n",
    "\n",
    "pysam is a lightweight wrapper of the htslib C-API and provides facilities to read and write SAM/BAM/VCF/BCF/BED/GFF/GTF/FASTA/FASTQ files as well as access to the command line functionality of the samtools and bcftools packages. The module supports compression and random access through indexing.\n",
    "\n",
    "This module provides a low-level wrapper around the htslib C-API as using cython and a high-level API for convenient access to the data within standard genomic file formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-distributor",
   "metadata": {},
   "source": [
    "pip install velocyto (Conda is not available)\n",
    "conda install R rpy2 (recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-mileage",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "After you have velocyto correctly installed on your machine (see installation tutorial) the velocyto command will become available in the terminal. velocyto is a command line tool with subcomands. You can get quick info on all the available commands typing velocyto --help. You will get the following output.\n",
    "\n",
    "The general purpose command to run the read counting pipeline is velocyto run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-water",
   "metadata": {},
   "source": [
    "### run10x - Run on 10X Chromium samples\n",
    "\n",
    "https://bauercore.fas.harvard.edu/10x-chromium-system\n",
    "\n",
    "10x Genomics' Chromium technology partitions reactions into nanoliter-scale droplets containing uniquely barcoded beads called GEMs (Gel Bead-In EMulsions). This core technology can be used to partition single cells, nuclei, or high molecular weight gDNA to prepare next generation sequencing libraries in parallel. We provide training and run samples as a service on the Chromium system. Please contact Claire Reardon to discuss your experimental plans. \n",
    "\n",
    "Single Cell 3' and 5' Workflow\n",
    "10x single-cell 3' and 5' assays partition individual cells into GEMs that uniquely barcode hundreds to thousands of cells with a capture efficiency of 65%. 3’ or 5' end counting determines gene expression and characterizes cells of a heterogeneous population. In addition to expression profiling, the 5' assay enables immune profiling by enriching barcoded cDNA for V(D)J sequences of T or B cells. Both the 3' and 5' assays can be combined with \"Feature Barcoding\" technology which determines expression of cell-surface proteins through oligo-labelled antibodies.\n",
    "\n",
    "Single Cell ATAC Workflow\n",
    "The single cell ATAC assay allows for determination of the accessibility of chromatin on a single cell level. A sample of hundreds to thousands of nuclei undergoes a transposition reaction and the transposed nuclei are then partitioned into GEMs which uniquely barcode accessible DNA fragments. \n",
    "\n",
    "Genome Assay Workflow\n",
    "The genome assay partitions high molecular weight (HMW) DNA into individual GEMs to capture long-range information using Illumina next-generation sequencing. The assay requires low input of high molecular weight DNA and produces \"linked read\" information which can be used to assemble genomes, assess structural variants, and phase across haplotype blocks >10 Mb.Please contact Claire Reardon to discuss your experimental plans.\n",
    "\n",
    "### run_smartseq2 - Run on SmartSeq2 samples\n",
    "\n",
    "Smart-Seq2\n",
    "https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/smart-seq2.html\n",
    "\n",
    "Method Category: Transcriptome > RNA Low-Level Detection\n",
    "\n",
    "Description: For Smart-Seq2, single cells are lysed in a buffer that contains free dNTPs and oligo(dT)-tailed oligonucleotides with a universal 5'-anchor sequence. RT is performed, which adds 25 untemplated nucleotides to the cDNA 3′ end. A template-switching oligo (TSO) is added, carrying 2 riboguanosines and a modified guanosine to produce a LNA as the last base at the 3′ end. After the first-strand reaction, the cDNA is amplified using a limited number of cycles. Next, tagmentation is used to construct sequencing libraries quickly and efficiently from the amplified cDNA.\n",
    "\n",
    "Pros:\n",
    "As little as 50 pg of starting material can be used\n",
    "mRNA sequence does not have to be known\n",
    "Improved coverage across transcripts\n",
    "High level of mappable reads\n",
    "Cons:\n",
    "Not strand-specific\n",
    "No early multiplexing\n",
    "Transcript length bias, with inefficient transcription of reads over 4 Kb\n",
    "Preferential amplification of high-abundance transcripts\n",
    "Purification step may lead to loss of material\n",
    "Could be subject to strand-invasion bias\n",
    "\n",
    "### run_dropest - Run on DropSeq, InDrops and other techniques\n",
    "\n",
    "Drop-Seq\n",
    "https://www.illumina.com/science/sequencing-method-explorer/kits-and-arrays/drop-seq.html\n",
    "\n",
    "Method Category: Transcriptome > RNA Low-Level Detection\n",
    "\n",
    "Description: Drop-Seq analyzes mRNA transcripts from droplets of individual cells in a highly parallel fashion. This single-cell sequencing method uses a microfluidic device to compartmentalize droplets containing a single cell, lysis buffer, and a microbead covered with barcoded primers. Each primer contains: 1) a 30 bp oligo(dT) sequence to bind mRNAs; 2) an 8 bp molecular index to identify each mRNA strand uniquely; 3) a 12 bp barcode unique to each cell and 4) a universal sequence identical across all beads. Following compartmentalization, cells in the droplets are lysed and the released mRNA hybridizes to the oligo(dT) tract of the primer beads. Next, all droplets are pooled and broken to release the beads within. After the beads are isolated, they are reverse-transcribed with template switching. This generates the first cDNA strand with a PCR primer sequence in place of the universal sequence. cDNAs are PCR-amplified, and sequencing adapters are added using the Nextera XT Library Preparation Kit. The barcoded mRNA samples are ready for sequencing.\n",
    "\n",
    "Similar methods: CEL-Seq, Quartz-Seq, MARS-Seq, CytoSeq, inDrop, Hi-SCL.\n",
    "\n",
    "Pros:\n",
    "Analyze sequences of single-cells in a highly parallel manner\n",
    "Unique molecular and cell barcodes enables cell and gene specific identification of mRNA strands\n",
    "Reverse transcription with template-switching PCR produce high-yield reads from single cells\n",
    "Low cost - $0.07 per cell ($653 per 10,000 cells) and fast library prep (10,000 cells per day)\n",
    "Cons:\n",
    "Requires custom microfluidics device to perform droplet separation\n",
    "Low gene-per-cell sensitivity compared to other scRNA-Seq methods\n",
    "Limited to mRNA transcripts\n",
    "\n",
    "\n",
    "### first runtime and parallelization\n",
    "\n",
    "As one of its first steps velocyto run will try to create a copy of the input .bam files sorted by cell-barcode. The sorted .bam file will be placed in the same directory as the original file and it will be named cellsorted_[ORIGINALBAMNAME]. The sorting procedure uses samtools sort and it is expected to be time consumning, because of this, the procedurre is perfomed in parellel by default. It is possible to control this parallelization using the parameters --samtools-threads and --samtools-memory\n",
    "\n",
    "### Requirements on the input files\n",
    "velocyto assumes that the bam file that is passed to the CLI contains a set of information and that some upstream analysis was performed on them already. In particular the bam file will have to:\n",
    "\n",
    "Be sorted by mapping position.\n",
    "Represents either a single sample (multiple cells prepared using a certain barcode set in a single experiment) or single cell.\n",
    "Contain an error corrected cell barcodes as a TAG named CB or XC.\n",
    "Contain an error corrected molecular barcodes as a TAG named UB or XM.\n",
    "\n",
    "\n",
    "### About the output .loom file\n",
    "The main result file is a 4-layered loom file : sample_id.loom.\n",
    "\n",
    "A valid .loom file is simply an HDF5 file that contains specific groups representing the main matrix as well as row and column attributes. Because of this, .loom files can be created and read by any language that supports HDF5.\n",
    "\n",
    ".loom files can be easily handled using the loompy package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-miracle",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Velocyto Loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import velocyto as vcy\n",
    "vlm = vcy.VelocytoLoom(\"YourData.loom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-intersection",
   "metadata": {},
   "source": [
    "Different steps of analysis can be carried on by simply calling the methods of this VelocytoLoom object. New variables, normalized version of the data matrixes and other parameters will be stored as attributes of the “VelocytoLoom” object (method calls will not return any value). For example normalization and log transformation can be performed by calling the normalize method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm.normalize(\"S\", size=True, log=True)\n",
    "vlm.S_norm  # contains log normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-spending",
   "metadata": {},
   "source": [
    "The docstring of every function specifies which attributes will be generated or modified at each method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-secondary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-gentleman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-still",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-imperial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-sally",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-testament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-arrest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-structure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-composition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
