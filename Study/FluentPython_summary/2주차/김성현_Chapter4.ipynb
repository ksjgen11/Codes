{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"김성현_Chapter4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNv3XoFPpW+Kzqup3WxB5UB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"emHeyrjpO7mX","colab_type":"text"},"source":["## Chapter 4\n","\n","4단원은 주로 문자열 인코딩에 대해 다룬다. 파이썬은 기본적으로 코드를 utf-8 로 처리하는데, 따라서 다음과 같은 코드를 작성할 수도 있다. 한글로 변수명 등을 지을 수 있는 것이다! 물론 함수명도 가능하다."]},{"cell_type":"code","metadata":{"id":"dbvcMNCkHIUo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600002799294,"user_tz":-540,"elapsed":1885,"user":{"displayName":"김성현","photoUrl":"","userId":"08481702398705998284"}},"outputId":"a1b54d7c-8f98-4a77-a6fc-c8769b89838d"},"source":["성=\"김\"\n","이름=\"성현\"\n","출력=print\n","성명=성+이름\n","출력(성명)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["김성현\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ERTVAxmoHIhX","colab_type":"text"},"source":["파이썬에는 기본적으로 문자열을 유니코드로 취급한다. 물론 파이썬2에서는 u\"\"를 이용해 유니코드를 취급해야 했다.(이를 위한 codecs 라이브러리가 따로 있었다) 파이썬 2로 코드를 짠 적이 있었는데 유니코드 문자열을 취급하기 위해서 여러가지 귀찮은 절차가 있었다. 그런데 파이썬3부터는 문자열을 전부 utf-8 유니코드로 취급하기 시작했다. 즉 파이썬2의 unicode형과 파이썬3의 str은 상당히 비슷하다. 따라서 문자열을 다루기 상당히 편리해졌다. 그럼 이제 문자열의 다양한 문제들에 대해 알아보자. 다음 코드는 특수문자가 들어간 문자열을 utf-8로 인코딩하고 다시 디코딩한다. 인코딩하면 특수문자 때문에 문자열의 길이가 늘어나는 것을 볼 수 있다."]},{"cell_type":"code","metadata":{"id":"zPM5xtokP0Kt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1595400587691,"user_tz":-540,"elapsed":1422,"user":{"displayName":"김성현","photoUrl":"","userId":"08481702398705998284"}},"outputId":"ac7c108b-dd47-41ec-9231-6a1420c1d88d"},"source":["s=\"cafⓔ\"\n","print(len(s))\n","b=s.encode('utf-8')\n","print(b)\n","print(len(b))\n","b=b.decode('utf-8')\n","print(b)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4\n","b'caf\\xe2\\x93\\x94'\n","6\n","cafⓔ\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wQOTRhr-QebE","colab_type":"text"},"source":["+ 유니코드 문자 표현\n","\n","문자열을 구성하는 '문자' 를 가장 잘 정의하고 있는 건 현재로서는 유니코드 문자다. 이때 유니코드를 실제 어떤 바이트로 표현할지를 결정하는 것이 인코딩 방식이고 utf-8이나 utf16등 다양한 방식이 존재한다. 유니코드와 인코딩 방식은 같은 개념이 아니다. 파이썬에서는 문자열 str과 바이트bytes를 구분하고 있는데, encode와 decode 함수를 통해 둘을 변환할 수 있다. 문자열의 인코딩 방식을 지정해서 encode하면 bytes형이 되는 것이고 decode로는 반대의 작업을 할 수 있다. 다만 유니코드 문자를 '문자'의 정의로 사용하는 것이 타당하다는 사실은 어느 인코딩 방식을 사용하든 마찬가지다. 참고로 파이썬은 대부분 utf-8 인코딩을 사용하고 다른 곳에서도 그 방식을 많이 사용하고 있다.\n","\n","+ 유니코드 인코딩 방식\n","\n","utf-8등의 다양한 인코딩 방식은 `open(), str.encode(), bytes.decode()`등의 함수의 encoding인수에 전달해서 사용할 수 있다. 파이썬은 ascii, latin1, utf8 등 다양한 방식의 인코더/디코더를 지원하고 있다. 단 ascii나 latin1 과 같은 방식은 표현할 수 없는 문자가 있을 때가 있다. utf8이나 utf16등이 가장 일반적이고 모든 유니코드 문자를 표현할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"K6uIneGhJA6f","colab_type":"text"},"source":["+ 인코딩할 수 없는 문자\n","\n","latin1이나 cp437과 같은, utf가 아닌 코덱의 경우 유니코드 문자 중 처리할 수 없는 문자들이 있다. 이런 문자들을 처리하려고 시도할 경우 `UnicodeEncodeError`가 발생하는데, `encode()`함수에 errors 인수를 줌으로써 이를 해결할 수 있다.\n","`errors='ignore'` 이면 인코딩할 수 없는 문자를 건너뛰고\n","`errors='replace'` 이면 인코딩할 수 없는 문자를 ?로 처리하고\n","`errors='xmlcharrefreplace'` 이면 인코딩할 수 없는 문자를 xml개체로 치환한다.\n","\n","+ 디코딩할 수 없는 문자\n","\n","또한 byte를 디코딩할 때도 비슷한 문제가 발생할 수 있는데, 모든 바이트 표현이 아스키 문자가 되는 것은 아니기 때문이다. 모든 바이트 시퀀스가 유니코드 문자와 대응되는 것은 아니다. 이럴 때는 `UnicodeDecodeError`가 발생하며 decode 함수에 `errors='replace'`등의 인수를 주는 것으로 해결할 수 있다. 또한 `cp1252`와 같은 레거시 코덱들의 경우 무작위 비트 배열에 대해서도 조용히 바이트 스트림으로 디코딩을 진행한다. 따라서 제대로 디코딩할 수 없는 쓰레기 문자에 대해서도, 코덱에 따라 에러가 발생하지 않을 수도 있다.\n","\n","+ 소스코드 인코딩 방식\n","\n","또한 파이썬3부터는 utf-8을 소스코드의 기본 인코딩 방식으로 사용하기 때문에, utf-8이 아닌 형식으로 인코딩된 .py모듈을 로딩할 시 에러가 발생한다. 이는 파일 꼭대기에 `# coding : encoding`형식 의 주석을 달아 해결할 수 있다. 물론 보통은 그냥 utf-8로 변환하는 것이 좋다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XE35K8jnOhS7","colab_type":"text"},"source":["+ 텍스트 파일 다루기\n","\n","텍스트 파일을 다룰 때는, 책의 서술에 따르면 '유니코드 샌드위치' 방식을 쓰는 것이 가장 좋다. 파일을 입력할 때, 즉 파일을 읽기 위해 열 때는 최대한 빨리 bytes를 str로 디코딩해야 하고 str형태의 텍스트를 처리한 후, 최후에 파일을 출력할 때는 str을 bytes로 인코딩해서 출력한다. 중간에 str텍스트를 처리하는 도중에는 인코딩이나 디코딩을 시행하면 안 되고, 파일을 열고 닫을 때만 인코딩/디코딩을 해야 한다.\n","\n","* 다른 처리를 하는 동안 인코딩이나 디코딩을 하면 안 되는 것이다!\n","\n","* 파일을 열 떄의 인코딩 설정\n","\n","단 파일을 열 때 `open()` 함수에 encoding인수를 지정하지 않으면 기본 지역 설정에 따른 인코딩 방식을 사용하는데(보통은 `getpreferredencoding()` 을 호출해서 지정된다), 이는 여러 컴퓨터에서 실행해야 하는 코드를 짤 경우 매우 위험할 수 있다. 따라서 텍스트 파일을 읽을 때는 언제나\n","`open('foo.txt', 'r', encoding='utf8')` 등으로 encoding인수를 통해 인코딩 형식을 명시적으로 지정해 줘야 한다. 기본 인코딩 설정에 의존하다가는 문제가 발생하기 쉽다.\n","\n"]},{"cell_type":"code","metadata":{"id":"CV9d3mGkSCIn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1595401009425,"user_tz":-540,"elapsed":788,"user":{"displayName":"김성현","photoUrl":"","userId":"08481702398705998284"}},"outputId":"4f4065bf-ce56-4945-b795-db585074597b"},"source":["s1=\"café\"\n","s2=\"cafe\\u0301\"\n","print(s1,s2)\n","print(len(s1),len(s2))\n","print(s1==s2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["café café\n","4 5\n","False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"67E20rzkT5N-","colab_type":"text"},"source":["+ 유니코드 정규화\n","\n","위와 같은 코드를 보면, 악센트 기호를 분리해서 코드 포인트로 넣어 줄 시 문자열 비교가 제대로 되지 않는 현상이 생긴다. 규범적으로 동일한 문자열을 파이썬은 '다르다' 고 판단하는 것이다. 이를 위해서는 유니코드 정규화가 필요하고 그걸 해주는 unicodedata.normalize() 함수가 이미 존재한다. 그 함수의 첫번째 인수는 NFC, NFD, NFKC, NFKD 중 하나인데 다 각각의 특징이 있다. 하지만 유니코드 정규화를 한다는 목적은 동일하다.\n","\n","NFC는 코드 포인트를 조합하여 가장 짧은 동일 문자열을 구성하고, NFD는 조합된 문자를 기본 문자와 별도의 결합 문자로 분리한다. 따라서 NFD가 문자열은 좀 더 길어질 수 있다."]},{"cell_type":"code","metadata":{"id":"a4JeB-3maT6B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1595402809993,"user_tz":-540,"elapsed":797,"user":{"displayName":"김성현","photoUrl":"","userId":"08481702398705998284"}},"outputId":"fa807fad-feec-4526-943c-65eeaa734e2b"},"source":["from unicodedata import normalize\n","s1=\"café\"\n","s2=\"cafe\\u0301\"\n","print(s1==s2)\n","print(normalize('NFC',s1)==normalize('NFC',s2))\n","print(len(normalize('NFC',s1)), len(normalize('NFC',s2)))\n","print(normalize('NFD',s1)==normalize('NFD',s2))\n","print(len(normalize('NFD',s1)), len(normalize('NFD',s2)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["False\n","True\n","4 4\n","True\n","5 5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"79QEQ-4oa1tX","colab_type":"text"},"source":["+ K가 붙은 정규화 방식\n","\n","NFKC와 NFKD는 정규화의 다른 형태로, K는 호환성을 나타낸다. 이는 기존 표준과의 호환성을 위해 두 번 이상 나타나는 문자도 있는 문제와 연관이 있다(즉 하나의 기호가 두 개 이상의 코드 포인트로 표현되는 것). 이때 NFKC와 NFKD는 호환성 문자를 호환성 분할로 치환시킨다. 이 과정에서 손실이 일어날 수도 있다. 따라서 조심해서 사용해야 하는 정규화 방식이다. 이런 것을 고려할 때, NFC가 가장 많이 쓰이는 정규화 방식이다."]},{"cell_type":"markdown","metadata":{"id":"8YGZj0Gp3SjJ","colab_type":"text"},"source":["+ 유니코드 문자의 크기\n","\n","아스키 코드의 경우에는 1문자==1바이트지만 유니코드의 경우 얼마든지 1글자가 2바이트, 혹은 3바이트의 바이트 시퀀스로 표현될 수 있다. 따라서 문자열을 처리할 때는 유니코드임을 생각하며 늘 조심해서 처리해야 한다. 이를테면 서로 비교할 때 정규화해서 비교한다든지, 특정 인코딩에 따라서 처리할 수 없는 문자가 있음을 생각하고 처리한다든지.(물론 파이썬은 기본적으로 utf-8을 사용하지만)"]}]}